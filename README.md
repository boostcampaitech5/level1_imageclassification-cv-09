# ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦

ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AItech 5ê¸° CV_9íŒ€ level-1(image classification) í”„ë¡œì íŠ¸ ê³µê°„ì…ë‹ˆë‹¤.

![image](https://user-images.githubusercontent.com/72616557/228166051-e8197cb8-0025-485d-becc-cba4a5c257fd.png)



## Contributors

|ì‹ í˜„ì¤€ |                                                  í•œí˜„ë¯¼|ì •í˜„ì„ |                                                  ê¹€ì§€ë²”|ì˜¤ìœ ë¦¼|
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| [<img src="https://avatars.githubusercontent.com/u/113486402?s=400&v=4" alt="" style="width:100px;100px;">](https://github.com/june95) <br/> | [<img src="https://avatars.githubusercontent.com/u/33598545?s=400&u=d0aaa9e96fd2fa1d0c1aa034d8e9e2c8daf96473&v=4" alt="" style="width:100px;100px;">](https://github.com/Hyunmin-H) <br/> | [<img src="https://avatars.githubusercontent.com/u/72616557?v=4" alt="" style="width:100px;100px;">](https://github.com/hyuns66) <br/> | [<img src="https://avatars.githubusercontent.com/u/91449518?v=4" alt="" style="width:100px;100px;">](https://github.com/jibeomkim7) <br/> |[<img src="https://avatars.githubusercontent.com/u/63313306?s=400&u=094cba544d8029b4f93aa191d036a109d6265fa8&v=4" alt="" style="width:100px;100px;">](https://github.com/jennifer060697) <br/> |


í•´ë‹¹ í”„ë¡œì íŠ¸ repositoryì—ì„œ ì°¸ê³ í•œ reference ëª©ë¡ì…ë‹ˆë‹¤.

Model soups : [Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time](https://arxiv.org/abs/2203.05482).

ViT : https://github.com/google-research/vision_transformer


## Setting Step
### 1. ê°€ìƒ í™˜ê²½ ì„¤ì¹˜  
```bash
conda env create -f environment.yml
conda activate model_soups
```
### 2. ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
- wandb, albumentations ë“± ì¶”ê°€ ì„¤ì¹˜  
### 3. pretrained model ë‹¤ìš´ë¡œë“œ  
```bash
python main.py --download-models --model-location <where models will be stored>  
```

## ì‹¤í–‰ Step  
### 1. Fine Tuning
```bash
python finetune.py --name {ëª¨ë¸ëª…} --i {ëª¨ë¸ number} --batch-size {ë°°ì¹˜ ì‚¬ì´ì¦ˆ(ex:256)} --epochs {ì—í­ ìˆ˜(ex:10)} --random-seed {ì‹œë“œ ì„¤ì •}
```
- ImageNet ë“±ì„ ì´ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµí•œ ëª¨ë¸ parameterë¥¼ ì´ìš©í•˜ì—¬, ìš°ë¦¬ì˜ ë°ì´í„°ì…‹ì— ë§ê²Œ ë§ˆì§€ë§‰ layerë¥¼ ë°”ê¿”ì£¼ê³  í•™ìŠµí•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
- ëª¨ë¸ number rangeëŠ” 0~71(72ê°œ ì…ë‹ˆë‹¤.)  
- ì €ì¥ë˜ëŠ” ëª¨ë¸ pt íŒŒì¼ëª…ì€ "ëª¨ë¸ëª…i_epochs10.pt"
- ì¶”ê°€ë¡œ learning rate, data-locationê³¼ ê°™ì€ argumentë“¤ì´ ìˆìœ¼ë©°, ëª¨ë“  argumentëŠ” default ê°’ì„ finetune.pyì—ì„œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- Tip : ì‰˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ìë™í™”í•˜ê¸° -> training.sh íŒŒì¼ ì‘ì„± í›„ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰
```bash
bash trining.sh
```

### 2. Individual Evaluation  
```bash
python main.py --eval-individual-models --name {ëª¨ë¸ëª…}
```
- finetuneì„ í†µí•´ ë§Œë“  ëª¨ë¸ë“¤ì˜ accuracyë¥¼ ì¸¡ì •í•˜ì—¬ ê¸°ë¡í•´ë‘ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
![image](https://user-images.githubusercontent.com/113486402/233948441-7bab18bc-37f8-424b-a0fb-3223a37781b8.png)
- "ì…ë ¥í•˜ì„¸ìš”" ë¶€ë¶„ì— ì¸¡ì •í•  ëª¨ë¸ì˜ ê°œìˆ˜(NUM_MODELS), ì‚¬ìš©í•  epoch, val_ratioë¥¼ ì ì–´ì¤ë‹ˆë‹¤.
- val_ratioì— None ê°’ì„ ì…ë ¥í•˜ë©´, ì „ì²´ datasetì— ëŒ€í•´ evaludationì„ ì§„í–‰í•©ë‹ˆë‹¤. 
- finetune ë‹¹ì‹œì— random-seedë¥¼ ì„¤ì •í•´ì£¼ì—ˆë‹¤ë©´, Noneê°’ì„ ë„£ì–´ì£¼ë©´ ì•ˆë©ë‹ˆë‹¤.
- ì‹¤í–‰ ê²°ê³¼ë¡œ logs í´ë” ì•ˆì— ê° ëª¨ë¸ì˜ accuracyê°€ ì íŒ jsonl íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. 

### 3. Greedy Soup
```bash
python main.py --greedy-soup --name {ëª¨ë¸ëª…}
```  
- individual Evaluationì—ì„œ ì €ì¥í•œ ì—¬ëŸ¬ ëª¨ë¸ì˜ accuracyì •ë³´ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.  
- ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ëª¨ë¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë¶ˆëŸ¬ì™€ greedyí•˜ê²Œ ì¡°í•©í•˜ì—¬(averaging) ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ë„ë¡ í•˜ëŠ” ìµœì¢… ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
- ì‹¤í–‰ ê²°ê³¼ model í´ë” ì•ˆì— greedy ëª¨ë¸ì´ ì €ì¥ë©ë‹ˆë‹¤.
- log í´ë” ì•ˆì— ë³€ìˆ˜ GREEDY_SOUP_LOG_FILEê°€ ì´ë¦„ì„ ë¡œê·¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. í•´ë‹¹ ë¡œê·¸ì—ëŠ” averagingëœ ëª¨ë¸ ì •ë³´ê°€ ì €ì¥ë©ë‹ˆë‹¤.

## Code

There are 5 steps to reproduced the figure above: 1) downloading the models, 2) evaluating the individual models, 3) running the uniform soup, 4) running the greedy soup, and 5) making the plot.

Note that any of these steps can be skipped, i.e, you can immediately generate the plot above via `python main.py --plot`.
You can also run the greedy soup without evaluating the individual models.
This is because we have already completed all of the steps and saved the results files in this repository (i.e., `individual_model_results.jsonl`).
If you do decide to rerun a step, the corresponding results file or plot is deleted and regenerated.

The exception is step 1, downloading the models. If you wish to run steps 2, 3, or 4 you must first run step 1.

### Install dependencies and downloading datasets

To install the dependencies either run the following code or see [environment.md](environment.md) for more information.
```bash
conda env create -f environment.yml
conda activate model_soups
```

To download the datasets see [datasets.md](datasets.md). When required, set `--data-location` to the `$DATA_LOCATION` used in [datasets.md](datasets.md).

### Step 1: Downloading the models

```bash
python main.py --download-models --model-location <where models will be stored>
```
This will store models to `--model-location`.


### Step 2: Evaluate individual models

```bash
python main.py --eval-individual-models --data-location <where data is stored> --model-location <where models are stored>
```
Note that this will first delete then rewrite the file `individual_model_results.jsonl`.

### Step 3: Uniform soup

```bash
python main.py --uniform-soup --data-location <where data is stored> --model-location <where models are stored>
```
Note that this will first delete then rewrite the file `uniform_soup_results.jsonl`.

### Step 4. Greedy soup

```bash
python main.py --greedy-soup --data-location <where data is stored> --model-location <where models are stored>
```
Note that this will first delete then rewrite the file `greedy_soup_results.jsonl`.

### Step 5. Plot

```bash
python main.py --plot
```
Note that this will first delete then rewrite the file `figure.png`.

### Note

If you want, you can all steps with:
```bash
python main.py --download-models --eval-individual-models --uniform-soup --greedy-soup --plot --data-location <where data is stored> --model-location <where models are stored>
```

Also note: if you are interested in running ensemble baselines, check out [the ensemble branch](https://github.com/mlfoundations/model-soups/tree/ensemble).

Also note: if you are interested in running a minial example of [wise-ft](https://arxiv.org/abs/2109.01903), you can run `python wise-ft-example.py --download-models`. 

Also note: if you are interested in running minimal examples of zeroshot/fine-tuning, you can run `python zeroshot.py` or `python finetune.py`. See program arguments (i.e., run with `--help`) for more information. Note that these are minimal examples and do not contain rand-aug, mixup, or LP-FT.

### Questions

If you have any questions please feel free to raise an issue. If there are any FAQ we will answer them here.

### Authors

This project is by the following authors, where * denotes equal contribution (alphabetical ordering):
- [Mitchell Wortsman](https://mitchellnw.github.io/)
- [Gabriel Ilharco](http://gabrielilharco.com/)
- [Samir Yitzhak Gadre](https://sagadre.github.io/)
- [Rebecca Roelofs](https://twitter.com/beccaroelofs)
- [Raphael Gontijo-Lopes](https://raphagl.com/)
- [Ari S. Morcos](http://www.arimorcos.com/)
- [Hongseok Namkoong](https://hsnamkoong.github.io/)
- [Ali Farhadi](https://homes.cs.washington.edu/~ali/)
- [Yair Carmon*](https://www.cs.tau.ac.il/~ycarmon/)
- [Simon Kornblith*](https://simonster.com/)
- [Ludwig Schmidt*](https://people.csail.mit.edu/ludwigs/)


## Citing

If you found this repository useful, please consider citing:
```bibtex
@InProceedings{pmlr-v162-wortsman22a,
  title = 	 {Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author =       {Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and Schmidt, Ludwig},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {23965--23998},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/wortsman22a/wortsman22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/wortsman22a.html}
}


```
