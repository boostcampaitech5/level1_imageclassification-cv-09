# ì•ˆë…•í•˜ì„¸ìš”! ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦

ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AItech 5ê¸° CV_9íŒ€ level-1(image classification) í”„ë¡œì íŠ¸ ê³µê°„ì…ë‹ˆë‹¤.

![image](https://user-images.githubusercontent.com/72616557/228166051-e8197cb8-0025-485d-becc-cba4a5c257fd.png)



## Contributors

|ì‹ í˜„ì¤€ |                                                  í•œí˜„ë¯¼|ì •í˜„ì„ |                                                  ê¹€ì§€ë²”|ì˜¤ìœ ë¦¼|
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| [<img src="https://avatars.githubusercontent.com/u/113486402?s=400&v=4" alt="" style="width:100px;100px;">](https://github.com/june95) <br/> | [<img src="https://avatars.githubusercontent.com/u/33598545?s=400&u=d0aaa9e96fd2fa1d0c1aa034d8e9e2c8daf96473&v=4" alt="" style="width:100px;100px;">](https://github.com/Hyunmin-H) <br/> | [<img src="https://avatars.githubusercontent.com/u/72616557?v=4" alt="" style="width:100px;100px;">](https://github.com/hyuns66) <br/> | [<img src="https://avatars.githubusercontent.com/u/91449518?v=4" alt="" style="width:100px;100px;">](https://github.com/jibeomkim7) <br/> |[<img src="https://avatars.githubusercontent.com/u/63313306?s=400&u=094cba544d8029b4f93aa191d036a109d6265fa8&v=4" alt="" style="width:100px;100px;">](https://github.com/jennifer060697) <br/> |


í•´ë‹¹ í”„ë¡œì íŠ¸ repositoryì—ì„œ ì°¸ê³ í•œ reference ëª©ë¡ì…ë‹ˆë‹¤.

Model soups : [Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time](https://arxiv.org/abs/2203.05482).

ViT : https://github.com/google-research/vision_transformer

  
## Setting Step
### 1. ê°€ìƒ í™˜ê²½ ì„¤ì¹˜  
```bash
conda env create -f environment.yml
conda activate model_soups
```
### 2. ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
- wandb, albumentations ë“± ì¶”ê°€ ì„¤ì¹˜  
### 3. pretrained model ë‹¤ìš´ë¡œë“œ  
```bash
python main.py --download-models --model-location <where models will be stored>  
```
  
## Training Step  
### 1. ViT-B/32 / ViT-B/16
### 1-1. Fine Tuning
```bash
python finetune.py --name {ëª¨ë¸ëª…} --i {ëª¨ë¸ number} --batch-size {ë°°ì¹˜ ì‚¬ì´ì¦ˆ(ex:256)} --epochs {ì—í­ ìˆ˜(ex:10)} --random-seed {ì‹œë“œ ì„¤ì •}
```
- ImageNet ë“±ì„ ì´ìš©í•˜ì—¬ ë¯¸ë¦¬ í•™ìŠµí•œ ëª¨ë¸ parameterë¥¼ ì´ìš©í•˜ì—¬, ìš°ë¦¬ì˜ ë°ì´í„°ì…‹ì— ë§ê²Œ ë§ˆì§€ë§‰ layerë¥¼ ë°”ê¿”ì£¼ê³  í•™ìŠµí•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
- ëª¨ë¸ number rangeëŠ” 0~71(72ê°œ ì…ë‹ˆë‹¤.)  
- ì €ì¥ë˜ëŠ” ëª¨ë¸ pt íŒŒì¼ëª…ì€ "ëª¨ë¸ëª…i_epochs10.pt"
- "--model {ViT-B/32 | ViT-B/16}" argument ì´ìš©í•˜ì—¬, base ëª¨ë¸ ì„¤ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
- ì¶”ê°€ë¡œ learning rate, data-locationê³¼ ê°™ì€ argumentë“¤ì´ ìˆìœ¼ë©°, ëª¨ë“  argumentëŠ” default ê°’ì„ finetune.pyì—ì„œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- Tip : ì‰˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ìë™í™”í•˜ê¸° -> training.sh íŒŒì¼ ì‘ì„± í›„ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰
```bash
bash trining.sh
``` 
#### 1-2. Data oversampling ì—¬ë¶€ ì„¤ì •
```bash  
python finetune.py --old-aug True
```  
- ì €í¬ëŠ” Old classì˜ train datasetì´ ì ì€ ê²ƒì„ ì–´ëŠì •ë„ í•´ê²°í•˜ê¸° ìœ„í•´ Old class dataë§Œ ì¶”ê°€ë¡œ over sampling í•˜ëŠ” ì½”ë“œ ë˜í•œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.  
- finetune íŒŒì¼ì„ ì‹¤í–‰í•  ë•Œì—, "--old-aug True" ë¡œ argumentë¥¼ ì¶”ê°€í•´ì£¼ë©´, Old class dataë§Œ í•œ ë²ˆ ë” ì¶”ê°€í•˜ì—¬ í•™ìŠµí•˜ë„ë¡ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
- í•´ë‹¹ dataì— augmentationì„ ë”°ë¡œ ì„¤ì •í•´ì£¼ê¸° ìœ„í•´, maskbasedataset.py ì—ì„œ get_transform í•¨ìˆ˜ì— ì¶”ê°€ë¡œ 'train2' augmentationì„ ì¶”ê°€í•´ ì£¼ì—ˆìŠµë‹ˆë‹¤.
#### 1-3. Loss Function ì„¤ì •
```bash
python finetune.py --loss-fn {CrossEntropyLoss | ContrastiveLoss}
```  
- default loss functionì€ CrossEntropyLoss ì´ë©°, ContrastiveLossë¥¼ ì‚¬ìš© ì‹œì—, argumentë¥¼ ì„¤ì •í•´ì£¼ë©´ ë©ë‹ˆë‹¤.


### 2. Model Soups
#### 2-1. Fine Tuning
- model soupsëŠ” ViT-B/32 ëª¨ë¸ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ê¸° ë•Œë¬¸ì—, 1-1 ì˜ Fine Tuningì—ì„œ "--model ViT-B/32" argumentë¥¼ ì´ìš©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´ ì™¸ì˜ ì‚¬ìš©ë²•ì€ 1-1 ê³¼ ë™ì¼í•©ë‹ˆë‹¤.

#### 2-2. Individual Evaluation  
```bash
python main.py --eval-individual-models --name {ëª¨ë¸ëª…}
```
- finetuneì„ í†µí•´ ë§Œë“  ëª¨ë¸ë“¤ì˜ accuracyë¥¼ ì¸¡ì •í•˜ì—¬ ê¸°ë¡í•´ë‘ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
- ì¶”ê°€ argumentë¡œ ëª¨ë¸ì˜ ê°œìˆ˜(NUM_MODELS), ëª¨ë¸ì—ì„œ ì‚¬ìš©í•œ epoch, val_ratioë¥¼ ì ì–´ì¤ë‹ˆë‹¤.
- val_ratioì— None ê°’ì„ ì…ë ¥í•˜ë©´, ì „ì²´ datasetì— ëŒ€í•´ evaludationì„ ì§„í–‰í•©ë‹ˆë‹¤. 
- finetune ë‹¹ì‹œì— random-seedë¥¼ ì„¤ì •í•´ì£¼ì—ˆë‹¤ë©´, Noneê°’ì„ ë„£ì–´ì£¼ë©´ ì•ˆë©ë‹ˆë‹¤.
- ì‹¤í–‰ ê²°ê³¼ë¡œ logs í´ë” ì•ˆì— ê° ëª¨ë¸ì˜ accuracyê°€ ì íŒ jsonl íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. 

### 2-3. Greedy Soup
```bash
python main.py --greedy-soup --name {ëª¨ë¸ëª…}
```  
- individual Evaluationì—ì„œ ì €ì¥í•œ ì—¬ëŸ¬ ëª¨ë¸ì˜ accuracyì •ë³´ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.  
- ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ” ëª¨ë¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ë¶ˆëŸ¬ì™€ greedyí•˜ê²Œ ì¡°í•©í•˜ì—¬(averaging) ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ë„ë¡ í•˜ëŠ” ìµœì¢… ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
- ì‹¤í–‰ ê²°ê³¼ model í´ë” ì•ˆì— greedy ëª¨ë¸ì´ ì €ì¥ë©ë‹ˆë‹¤.
- log í´ë” ì•ˆì— ë³€ìˆ˜ GREEDY_SOUP_LOG_FILEê°€ ì´ë¦„ì„ ë¡œê·¸ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. í•´ë‹¹ ë¡œê·¸ì—ëŠ” averagingëœ ëª¨ë¸ ì •ë³´ê°€ ì €ì¥ë©ë‹ˆë‹¤.


## Inference Step
### 1. Inference Step
```bash
python inference.py --model-name {ëª¨ë¸ëª….pt íŒŒì¼}
```
- ìƒì„±í•œ ëª¨ë¸ íŒŒì¼(.pt)ë¥¼ ì´ìš©í•˜ì—¬ Test dataë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.  
- argument ë‚´ì— pt íŒŒì¼ëª…ì„ ì ê³  ì‹¤í–‰ì‹œí‚µë‹ˆë‹¤.   
- ìµœì¢… ì˜ˆì¸¡í•œ csv íŒŒì¼ì´ output í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤. 

#### 1-1. Validation í™•ì¸
```bash
python validation.py --model-name {ëª¨ë¸ëª….pt íŒŒì¼}
```
- ìš°ë¦¬ê°€ í•™ìŠµí•œ ëª¨ë¸ì„ ê°€ì§€ê³  ë™ì¼í•œ validation setì—ì„œ ì–´ë–¤ classê°€ ì˜ˆì¸¡ì„ ì˜ëª»í–ˆëŠ”ì§€ ì¶œë ¥í•´ì£¼ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
- í•´ë‹¹ ëª¨ë¸.ptë¥¼ í•™ìŠµí–ˆì„ ë•Œ, ì‚¬ìš©í–ˆë˜ seed ê°’ì„ ë™ì¼í•˜ê²Œ ìœ ì§€í•´ ì£¼ì–´ì•¼ ì •í™•í•œ í™•ë¥ ê³¼ ì˜ˆì¸¡ê°’ì´ ë‚˜ì˜µë‹ˆë‹¤.
- ì•„ë˜ ê·¸ë¦¼ì€ ì¶œë ¥ ì˜ˆì‹œì…ë‹ˆë‹¤.   
![image](https://user-images.githubusercontent.com/113486402/234260857-a5175967-8a7c-4c0b-bcfd-a63f7fb1559c.png)

#### 1-2. Weighted Ensemble  
- "--weighted-ensemble" argumentë¥¼ ì´ìš©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#### 1-3. Soft voting (Ensemble)  
- "--soft-voting" argumentë¥¼ ì´ìš©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
#### 1-4. Hard voting (Ensemble)
- inference.py ë¥¼ í†µí•´ ì˜ˆì¸¡ëœ output.csv ì—¬ëŸ¬ê°œì˜ ê²°ê³¼ê°’ì„ ê°€ì§€ê³  ìµœì¢…ì ìœ¼ë¡œ hard votingì„ ìˆ˜í–‰í•˜ëŠ” Ensemble ë˜í•œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.  
- hard_voting.ipynb ì„ ì‹¤í–‰í•˜ì—¬, ì•™ìƒë¸”ì„ ì›í•˜ëŠ” csvë¥¼ ê°€ì§€ê³  hard votingì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
  
## ì¶”ê°€ ê¸°ëŠ¥
### 1. Relabeling  
![image](https://user-images.githubusercontent.com/113486402/233954582-70a43065-7586-483e-abf5-707e744eebb3.png)  
- relabelingì´ í•„ìš”í•œ id ëª©ë¡ì„ listì— ë„£ì–´ì„œ relabel_dict ë”•ì…”ë„ˆë¦¬ì— ë„£ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤.
- maskbasedataset.pyì—ì„œ ì¶”ê°€ë¡œ relabelingì´ í•„ìš”í•œ idê°€ ìˆë‹¤ë©´ ê°„ë‹¨í•˜ê²Œ í•´ë‹¹ listì— ë„£ì–´ì£¼ê¸°ë§Œ í•˜ë©´ relabelingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  

### 2. Optuna  
- 
